{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning wwith TensorFlow part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned patterns for our own problem.\n",
    "\n",
    "There are two main genefits:\n",
    "\n",
    "**1.** Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
    "\n",
    "**2.** Can levarage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and becoming one with the data\n",
    "- Get data (10% of 10 food classes from Food101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders (preparing the data)\n",
    "\n",
    "We will use `ImageDataGenerator` class to load in our images in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image\n",
      "Found 750 images belonging to 10 classes.\n",
      "Testing image\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training image\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size = IMAGE_SHAPE,\n",
    "                                                          batch_size = BATCH_SIZE,\n",
    "                                                          class_mode = \"categorical\")\n",
    "\n",
    "print(\"Testing image\")\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                             target_size = IMAGE_SHAPE,\n",
    "                                             batch_size = BATCH_SIZE,\n",
    "                                              class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up callbacks (things to run whilst or model trains)\n",
    "\n",
    "Callbacks are extra functionality you can add to your model to be performed during or after training. Some of the mosr popular callbacks are:\n",
    "\n",
    "**1.** Tracking experience with the `TensorBoard` callback\n",
    "\n",
    "**2.** Model checkpoint with the `ModelCheckPoint` callback\n",
    "\n",
    "**3.** Stooping a model from training (before it trains too long and overfits) with the `EarlyStopping` cllback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard callback and functionized\n",
    "\n",
    "def create_TensorBoard_callback(dir_name, experiment_name):\n",
    "\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"Saving TensorBoard lod files to: {log_dir}\")\n",
    "    \n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a TensorFlow callback TensorBoard function. ðŸ¤–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model using TensorFlow Hub\n",
    "\n",
    "In the past we used TensorFlow to create our own modles layer by layer from scratch.\n",
    "\n",
    "Now we are going to do similar procedd, expect the majroity of our model's layers are goind to come from TensorFlow Hub.\n",
    "\n",
    "We can access pre-traied models on: [TfHub.dev](https://www.kaggle.com/models?tfhub-redirect=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare the following two models\n",
    "resnet_url = \"https://kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-feature-vector/versions/1\"\n",
    "\n",
    "efficientnet_url = \"https://www.kaggle.com/models/tensorflow/efficientnet/frameworks/TensorFlow2/variations/b0-feature-vector/versions/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a create_model() function to create a model from URL\n",
    "\n",
    "def create_model(modle_URL, num_classes=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Take a TensorFlow Hub URL and create a Keras Sequential model with it.\n",
    "    \"\"\"\n",
    "\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(modle_URL,\n",
    "                                             trainable=False, # Freeze the already patterns\n",
    "                                             name=\"Feature_Extractions\",\n",
    "                                             input_shape=IMAGE_SHAPE+(3,))\n",
    "    \n",
    "    # Create our own model\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_extractor_layer,\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', name=\"output_layer\")\n",
    "    ])\n",
    "\n",
    "    # Return\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ResNet TensorFlow Hub Feature Extraction Model ðŸ‘»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "# Create resnet model\n",
    "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Feature_Extractions (KerasL  (None, 2048)             23564800  \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,585,290\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Because we set trainable=`False`. Hence Non-trainable params: 23,564,800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard lod files to: tensorflow_hub/resnet50V2/20240204-235606\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-04 23:56:07.081375: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 53s 2s/step - loss: 0.6972 - accuracy: 0.7893 - val_loss: 0.7544 - val_accuracy: 0.7524\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.4582 - accuracy: 0.8747 - val_loss: 0.6858 - val_accuracy: 0.7764\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.3370 - accuracy: 0.9280 - val_loss: 0.6568 - val_accuracy: 0.7872\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.2673 - accuracy: 0.9520 - val_loss: 0.6467 - val_accuracy: 0.7880\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 53s 2s/step - loss: 0.2112 - accuracy: 0.9693 - val_loss: 0.6383 - val_accuracy: 0.7932\n"
     ]
    }
   ],
   "source": [
    "# Complie a model\n",
    "resnet_model.compile(\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "resnet_history = resnet_model.fit(train_data_10_percent,\n",
    "                 steps_per_epoch=len(train_data_10_percent),\n",
    "                 epochs=5,\n",
    "                 validation_data=test_data,\n",
    "                 callbacks=[create_TensorBoard_callback(\"tensorflow_hub\",\n",
    "                                                        experiment_name=\"resnet50V2\")]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
